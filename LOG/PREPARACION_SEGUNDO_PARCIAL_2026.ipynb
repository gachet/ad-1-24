{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPU1czq+FWcNxSDhFUAqAc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gachet/ad-1-24/blob/main/LOG/PREPARACION_SEGUNDO_PARCIAL_2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJcmGhhUvt-n"
      },
      "source": [
        "### Ejercicio Regresión Lineal Multivariable\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOSD98EKvt-p"
      },
      "source": [
        "#### Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oKKfcuIvt-q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qWBXWRLvt-r"
      },
      "source": [
        "#### Datos\n",
        "El siguiente conjunto de datos contiene la tensión arterial sistólica (mmHg) (variable dependiente a predecir), la edad (años) y el peso (libras, 1 libra = 0.39 Kg) (mmHg) (variables independientes o predictoras)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn2LF1Kivt-r",
        "outputId": "29718bee-a9a5-4445-a631-43efaf526e37",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: \n",
            "\n",
            "[[  1.  52. 173.]\n",
            " [  1.  59. 184.]\n",
            " [  1.  67. 194.]\n",
            " [  1.  73. 211.]\n",
            " [  1.  64. 196.]\n",
            " [  1.  74. 220.]\n",
            " [  1.  54. 188.]\n",
            " [  1.  61. 188.]\n",
            " [  1.  65. 207.]\n",
            " [  1.  46. 167.]\n",
            " [  1.  72. 217.]]\n"
          ]
        }
      ],
      "source": [
        "# X1 = systolic blood pressure; X2 = age in years, X3 = weight in pounds\n",
        "blood_pressure_data = np.array([\n",
        "    [132, 52, 173],\n",
        "    [143, 59, 184],\n",
        "    [153, 67, 194],\n",
        "    [162, 73, 211],\n",
        "    [154, 64, 196],\n",
        "    [168, 74, 220],\n",
        "    [137, 54, 188],\n",
        "    [149, 61, 188],\n",
        "    [159, 65, 207],\n",
        "    [128, 46, 167],\n",
        "    [166, 72, 217]\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suponiendo que tenemos una hipótesis de la forma  \n",
        "\n",
        "$h_{\\theta}(x)=\\theta^{T} x=\\theta_0+\\theta_1x_1+\\theta_2x_2$  \n",
        "No es necesario normalizar los datos.  \n",
        "Encontrar el vector $\\theta$ utilizando :  \n",
        "1.- Ecuaciones normales  \n",
        "2.- La librería SckitLearn  \n",
        "3.- En ambos casos calcular el error cuadrático medio dado por   \n",
        "$\\frac{1}{m} \\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2$   \n",
        "4.- Encontrar el vector $\\theta$ utilizando el algoritmo del gradiente descendente con los siguientes parámetros:  \n",
        "\n",
        "$max \\ iteraciones = 100000\\\\\n",
        "\\alpha = 0.00001\\\\\n",
        "\\epsilon = 10e-6$\n",
        "  \n",
        "5.- Cual es el mínimo coste $J(\\theta)$ obtenido con este método y con los dos primeros?  el algoritmo del gradiente converge ?  \n",
        "6.- Comentarios y conclusiones\n"
      ],
      "metadata": {
        "id": "io_NCWipoI39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Respuesta\n",
        "coefficients:\n",
        "\n",
        "[[30.99410295]\n",
        " [ 0.86141469]\n",
        " [ 0.3348592 ]]\n",
        ""
      ],
      "metadata": {
        "id": "GzvCkFCuJku4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ejercicio 2.- Para el conjunto de datos IRIS\n",
        "from sklearn import datasets  \n",
        "iris = datasets.load_iris()\n",
        "\n",
        "Sin normalizar los datos\n",
        "\n",
        "1.- Encontrar por regresión logistica mediante gradiente descendente\n",
        "los valores del vector $\\theta$ con los parámetros  \n",
        "num_iter = 250000  \n",
        "alpha = 0.1  \n",
        "Utilizar un valor razonable de epsilon,   \n",
        "Debería dar $\\theta$ , por cada clase (5 parámetros)\n",
        "\n",
        "theta:  [ 0.7794209   1.26223593  4.30162453 -6.8107031  -3.27548898]  \n",
        "theta:  [ 7.37848655 -0.24535671 -2.79656809  1.31364331 -2.77834391]  \n",
        "theta: [-22.82548815  -3.08449933  -5.31424996   7.24302427  12.90026622]\n",
        "\n",
        "2.- Obtener los valores utilizando la regresión logística con Sckitlearn y comparar,\n",
        "\n",
        "3,. Realizar una predicción para el conjunto de test Test  [6.4 2.8 5.6 2.2]  y comprobar por ambos métodos que se corresponde con la clase virginica.\n",
        "\n",
        "4.- Con SkitLearn, obtener las métricas del modelo y la matria de confusión."
      ],
      "metadata": {
        "id": "lLmERTUMPaeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 3.- Arbol de decisión con el conjunto (golf) visto en clase"
      ],
      "metadata": {
        "id": "a5Xf6wYMnnCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## import dependencies\n",
        "from sklearn import tree #For our Decision Tree\n",
        "import pandas as pd # For our DataFrame\n",
        "import pydotplus # To create our Decision Tree Graph\n",
        "from IPython.display import Image  # To Display a image of our graph"
      ],
      "metadata": {
        "id": "XbKwT0Qsn0x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the dataset empezando por utlook y terminando con \"Play\"\n",
        "#create empty data frame\n",
        "golf_df = pd.DataFrame()\n",
        "\n",
        "#add outlook\n",
        "golf_df['Outlook'] = ['sunny', 'sunny', 'overcast', 'rainy', 'rainy', 'rainy',\n",
        "                     'overcast', 'sunny', 'sunny', 'rainy', 'sunny', 'overcast',\n",
        "                     'overcast', 'rainy']\n",
        "...\n",
        "...\n",
        "...\n",
        "#finally add play\n",
        "golf_df['Play'] = ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes',\n",
        "                  'yes', 'yes', 'no']\n",
        "\n",
        "\n",
        "#Print/show the new data\n",
        "print(golf_df)"
      ],
      "metadata": {
        "id": "BEj4Smh5n1AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variable into dummy/indicator variables or (binary vairbles) essentialy 1's and 0's\n",
        "# I chose the variable name one_hot_data bescause in ML one-hot is a group of bits among which the legal combinations of values are only those with a single high (1) bit and all the others low (0)\n",
        "#MIRAR lo QUE hace la fución get_dummies\n",
        "one_hot_data = pd.get_dummies(golf_df[ ['Outlook', 'Temperature', 'Humidity', 'Windy'] ])"
      ],
      "metadata": {
        "id": "aS3-BP5En1JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the new dummy data\n",
        "one_hot_data"
      ],
      "metadata": {
        "id": "8fQOTY4kol5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.- Utlizando SkitLearn, construir un arbol de decisión utilizando el criterio **entropy** y profundidad 2.  \n",
        "2.- Visualizar el árbol construido.  \n",
        "3.- Utilizar el arbol para predecir el valor de \"play\" con  datos  \n",
        "Outlook = sunny,Temperature =  hot, Humidity = normal, Windy = false\n",
        "[0,0,1,0,1,0,0,1,1,0]  \n",
        "4.- Estudiar como se obtiene una matriz de confusión con un arbol de decisión y la libreria SKITLearn.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xGb_o14voq8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AIwZ_4muorI5"
      }
    }
  ]
}